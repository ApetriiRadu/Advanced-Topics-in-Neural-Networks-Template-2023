{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6xdc-kJSPqv"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torchvision.datasets import MNIST\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEuKSb8_Se7N",
        "outputId": "400a4843-fe1c-4931-b065-05638f98df4a"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def collate(x) -> Tensor:\n",
        "    if isinstance(x, (tuple, list)):\n",
        "        if isinstance(x[0], Tensor):\n",
        "            return torch.stack(x)\n",
        "        return torch.tensor(x)\n",
        "    raise \"Not supported yet\"\n",
        "\n",
        "\n",
        "def to_one_hot(x: Tensor) -> Tensor:\n",
        "    return torch.eye(x.max() + 1)[x]\n",
        "\n",
        "def load_mnist(path: str = \"./data\", train: bool = True):\n",
        "    mnist_raw = MNIST(path, download=True, train=train)\n",
        "    mnist_data = []\n",
        "    mnist_labels = []\n",
        "    for image, label in mnist_raw:\n",
        "        tensor = torch.from_numpy(np.array(image))\n",
        "        mnist_data.append(tensor)\n",
        "        mnist_labels.append(label)\n",
        "\n",
        "    mnist_data = collate(mnist_data).float()\n",
        "    mnist_data = mnist_data.flatten(start_dim=1)\n",
        "    mnist_data /= mnist_data.max()\n",
        "    mnist_labels = collate(mnist_labels)\n",
        "    if train:\n",
        "        mnist_labels1 = to_one_hot(mnist_labels)\n",
        "        return mnist_data, mnist_labels, mnist_labels1\n",
        "    return mnist_data, mnist_labels\n",
        "\n",
        "\n",
        "def activate(x: Tensor) -> Tensor:\n",
        "    return x.softmax(dim=1)\n",
        "\n",
        "def relu(x: Tensor) -> Tensor:\n",
        "    return torch.relu(x)\n",
        "\n",
        "def train_batch(x: Tensor, y: Tensor, w: Tensor, hidden_w: Tensor, b: Tensor, hidden_b: Tensor, lr: float, batch_size: int) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
        "    # Forward\n",
        "    hidden_forward = relu(x @ hidden_w + hidden_b)\n",
        "    forward = hidden_forward @ w + b\n",
        "    y_hat = activate(forward)\n",
        "\n",
        "    # Backward\n",
        "    error = y - y_hat\n",
        "    hidden_error = error @ w.T\n",
        "    delta_hidden_w = x.T @ hidden_error\n",
        "    delta_w = hidden_forward.T @ error\n",
        "    delta_hidden_b = hidden_error.mean(axis=0)\n",
        "    delta_b = error.mean(axis=0)\n",
        "\n",
        "    hidden_w += lr * delta_hidden_w / batch_size\n",
        "    hidden_b += lr * delta_hidden_b / batch_size\n",
        "    w += lr * delta_w / batch_size\n",
        "    b += lr * delta_b / batch_size\n",
        "    return w, b, hidden_w, hidden_b\n",
        "\n",
        "def train_epoch(data: Tensor, labels: Tensor, w: Tensor, hidden_w: Tensor, b: Tensor, hidden_b:Tensor, lr: float, batch_size: int) \\\n",
        "        -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
        "    for i in range(0, data.shape[0], batch_size):\n",
        "        x = data[i: i + batch_size].to(w.device)\n",
        "        y = labels[i: i + batch_size].to(w.device)\n",
        "        w, b, hidden_w, hidden_b = train_batch(x, y, w, hidden_w, b, hidden_b, lr, batch_size)\n",
        "    return w, b, hidden_w, hidden_b\n",
        "\n",
        "def evaluate(data: Tensor, labels: Tensor, w: Tensor, b: Tensor, hidden_w: Tensor, hidden_b: Tensor, batch_size: int, train: bool, epochs) -> float:\n",
        "    total_correct_predictions = 0\n",
        "    total_len = data.shape[0]\n",
        "    for i in range(0, total_len, batch_size):\n",
        "        x = data[i: i + batch_size].to(w.device)\n",
        "        y = labels[i: i + batch_size].to(w.device)\n",
        "        forward = relu(x @ hidden_w + hidden_b) @ w + b\n",
        "        predicted_distribution = activate(forward)\n",
        "        cross_entropy_result = torch.nn.functional.cross_entropy(forward, y)\n",
        "        # Both losses are computed, but they might be printed one over the other\n",
        "        # If one looks for a few seconds at the output, it will be able to see both losses\n",
        "        if train == True:\n",
        "            epochs.set_postfix_str(f\"Loss train: {cross_entropy_result}\")\n",
        "        else:\n",
        "            epochs.set_postfix_str(f\"Loss validation: {cross_entropy_result}\")\n",
        "        predicted_max_value, predicted_max_value_indices = torch.max(predicted_distribution, dim=1)\n",
        "        equality_mask = predicted_max_value_indices == y\n",
        "        correct_predictions = equality_mask.sum().item()\n",
        "        total_correct_predictions += correct_predictions\n",
        "\n",
        "    # print(total_correct_predictions, \"/\", total_len)\n",
        "    return total_correct_predictions / total_len\n",
        "\n",
        "def train(device: torch.device = get_default_device()):\n",
        "    w = torch.rand((100, 10), device = device)\n",
        "    hidden_w = torch.rand((784, 100), device = device)\n",
        "    b = torch.zeros((1, 10), device = device)\n",
        "    hidden_b = torch.zeros((1, 100), device = device)\n",
        "    lr = 0.06\n",
        "    batch_size = 128\n",
        "    data, labels_train, labels = load_mnist(train=True)\n",
        "    data_test, labels_test = load_mnist(train=False)\n",
        "    max_accuracy = 0.0\n",
        "    epoch_number = 100\n",
        "    epochs = tqdm(range(epoch_number))\n",
        "    for i in range(epoch_number):\n",
        "        print(\"Epoch: \", i)\n",
        "        w, b, hidden_w, hidden_b = train_epoch(data, labels, w, hidden_w, b, hidden_b, lr, batch_size)\n",
        "        train_accuracy = evaluate(data, labels_train, w, b, hidden_w, hidden_b, batch_size, True, epochs)\n",
        "        test_accuracy = evaluate(data_test, labels_test, w, b, hidden_w, hidden_b, batch_size, False, epochs)\n",
        "        print(\"Current test accuracy: \", test_accuracy)\n",
        "        max_accuracy = max(max_accuracy, test_accuracy)\n",
        "        if i > 0 and i % 25 == 0:\n",
        "            lr *= 0.5\n",
        "\n",
        "    print(\"Best accuracy: \", max_accuracy)\n",
        "\n",
        "train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
