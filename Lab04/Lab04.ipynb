{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "HqBT0RAuEJkQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plot\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUC0gE8DH8Bo"
      },
      "outputs": [],
      "source": [
        "!unzip Homework_Dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ScStZJgxEwi9",
        "outputId": "ce5972ed-918d-4783-d6f8-ea8316f7043a"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "class GlobalDataset(Dataset):\n",
        "    def __init__(self, base_dir, transform = None, device: torch.device = get_default_device()):\n",
        "        self.base_dir = base_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = {}\n",
        "        self.data = []\n",
        "        self.image_cache = {}\n",
        "        self.load()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        if item[0] in self.image_cache:\n",
        "            start_image = self.image_cache[item[0]]\n",
        "        else:\n",
        "            start_image = Image.open(item[0])\n",
        "            if self.transform:\n",
        "                start_image = self.transform(start_image)\n",
        "            start_image = start_image.reshape((1, 49152))\n",
        "            self.image_cache[item[0]] = start_image\n",
        "\n",
        "        if item[1] in self.image_cache:\n",
        "            end_image = self.image_cache[item[1]]\n",
        "        else:\n",
        "            end_image = Image.open(item[1])\n",
        "            if self.transform:\n",
        "                end_image = self.transform(end_image)\n",
        "            end_image = end_image.reshape((1, 49152))\n",
        "            self.image_cache[item[1]] = end_image\n",
        "\n",
        "        time_skip = item[2]\n",
        "        return start_image, end_image, time_skip\n",
        "\n",
        "    def compute_and_sort(self, date1, date2):\n",
        "        date1_split = date1.split('_')\n",
        "        year1 = int(date1_split[0])\n",
        "        month1 = int(date1_split[1])\n",
        "        date2_split = date2.split('_')\n",
        "        year2 = int(date2_split[0])\n",
        "        month2 = int(date2_split[1])\n",
        "\n",
        "        if year1 > year2 or (year1 == year2 and month1 >= month2):\n",
        "            return (year1 - year2) * 12 + month1 - month2, True\n",
        "        else:\n",
        "            return (year2 - year1) * 12 + month2 - month1, False\n",
        "\n",
        "    def load(self):\n",
        "        for dir in os.listdir(self.base_dir):\n",
        "            current_dir = os.path.join(os.path.join(self.base_dir, dir), \"images\")\n",
        "            for image_path in os.listdir(current_dir):\n",
        "                path = os.path.join(current_dir, image_path)\n",
        "                words = image_path.split('_')\n",
        "                year_month = words[2] + \"_\" + words[3]\n",
        "                if current_dir not in self.image_paths:\n",
        "                    self.image_paths[current_dir] = {}\n",
        "                self.image_paths[current_dir][path] = year_month\n",
        "        for dir in self.image_paths:\n",
        "            for path1 in self.image_paths[dir]:\n",
        "                for path2 in self.image_paths[dir]:\n",
        "                    months, first_bigger = self.compute_and_sort(self.image_paths[dir][path1], self.image_paths[dir][path2])\n",
        "                    if first_bigger:\n",
        "                        self.data.append([path2, path1, months])\n",
        "                    else:\n",
        "                        self.data.append([path1, path2, months])\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden1 = nn.Linear(49152, 128).to(device)\n",
        "        self.act1 = nn.ReLU().to(device)\n",
        "        self.hidden2 = nn.Linear(128, 64).to(device)\n",
        "        self.act2 = nn.ReLU().to(device)\n",
        "        self.output = nn.Linear(65, 49152).to(device)\n",
        "        self.act_output = nn.Sigmoid().to(device)\n",
        "\n",
        "    def forward(self, x, months):\n",
        "        x = self.act1(self.hidden1(x).to(device)).to(device)\n",
        "        x = self.act2(self.hidden2(x)).to(device)\n",
        "        months = months[:, None, None]\n",
        "        x = torch.concatenate((x, months), axis = 2)\n",
        "        x = self.output(x).to(device)\n",
        "        x = self.act_output(x).to(device)\n",
        "        return x\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.RandomRotation((-10, 10)), transforms.RandomGrayscale(0.15), transforms.RandomVerticalFlip(0.2)])\n",
        "global_dataset = GlobalDataset(base_dir = \"Homework Dataset\", transform = transform)\n",
        "\n",
        "train, validation, test = torch.utils.data.random_split(global_dataset, [0.7, 0.15, 0.15])\n",
        "\n",
        "train_loader = DataLoader(train, batch_size = 32, shuffle = True)\n",
        "validation_loader = DataLoader(validation, batch_size = 32, shuffle = False)\n",
        "test_loader = DataLoader(test, batch_size = 32, shuffle = False)\n",
        "\n",
        "model = Model()\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_accuracies = []\n",
        "train_losses = []\n",
        "validation_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "def train():\n",
        "    total = 0\n",
        "    ok = 0\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for mini_batch in train_loader:\n",
        "        data = torch.tensor(mini_batch[0], device = device)\n",
        "        label = torch.tensor(mini_batch[1], device = device)\n",
        "        y_pred = model(data, torch.tensor(mini_batch[2], device = device))\n",
        "        y = label\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += len(mini_batch)\n",
        "        ok += (y == y_pred).sum().item()\n",
        "        train_loss += loss.item()\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(ok / total)\n",
        "\n",
        "def val(test: bool):\n",
        "    total = 0\n",
        "    ok = 0\n",
        "    model.eval()\n",
        "    loader = validation_loader if test == False else test_loader\n",
        "    for item in loader:\n",
        "        data = torch.tensor(item[0], device = device)\n",
        "        label = torch.tensor(item[1], device = device)\n",
        "        y_pred = model(data, torch.tensor(item[2], device = device))\n",
        "        y = label\n",
        "        total += 1\n",
        "        ok += (y == y_pred).sum().item()\n",
        "    if test == False:\n",
        "        validation_accuracies.append(ok / total)\n",
        "    else:\n",
        "        test_accuracies.append(ok / total)\n",
        "\n",
        "def run(epoch_number: int):\n",
        "    epochs = tqdm(range(epoch_number))\n",
        "    for i in epochs:\n",
        "        train()\n",
        "        val(False)\n",
        "        epochs.set_postfix_str(f\"Train Loss: {train_losses[i]}, Train Accuracy: {train_accuracies[i]}, Validate Accuracy: {validation_accuracies[i]}\")\n",
        "    val(True)\n",
        "    print(f\"Test Accuracy: {test_accuracies[0]}\")\n",
        "\n",
        "run(epoch_number = 50)\n",
        "plot.plot(train_accuracies)\n",
        "plot.savefig(\"train_accuracies.png\")\n",
        "plot.clf()\n",
        "plot.plot(train_losses)\n",
        "plot.savefig(\"train_losses.png\")\n",
        "plot.clf()\n",
        "plot.plot(validation_accuracies)\n",
        "plot.savefig(\"validation_accuracies.png\")\n",
        "plot.clf()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
